{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Code: Gradient Boostin Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy as sp\n",
    "import glob as glob\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "full_data= pd.read_csv(\"/Users/jenniferpolson/Documents/School/2017-F/BE 223A/Final Project/features_encoded_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_bin(ytrue, ypred):\n",
    "    '''Creates the scoring metric for the GridSearchCV\n",
    "    '''\n",
    "    ypred_b = (ypred > 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(ytrue, ypred_b).ravel()\n",
    "    acc  = round((tp + tn)/(tp + tn + fp + fn)*100 , 3)\n",
    "    return acc\n",
    "\n",
    "\n",
    "scoring = {'Accuracy': make_scorer(acc_bin)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_boost_reg_CV (fold, total):\n",
    "    '''Performs Parameter Tuning on the Gradient Boost Regressor Model to produce probability labels for each entry in the test set.\n",
    "    Input: \n",
    "      - fold: the test data\n",
    "      - total: the entire dataset\n",
    "    \n",
    "    Output:\n",
    "      - test: the 'fold' dataset, with an addtional row added with the predictive labels\n",
    "    '''\n",
    "    test = full_data.loc[full_data['Folds'] == fold].dropna()\n",
    "    test_n = test.iloc[:, :-3]\n",
    "\n",
    "    train = pd.concat([full_data, test]).drop_duplicates(keep=False).dropna()\n",
    "    train_n = train.iloc[:, :-3]\n",
    "\n",
    "    trainArr = train_n.as_matrix()\n",
    "    trainRes = train.as_matrix(['Labels'])\n",
    "    testArr = test_n.as_matrix()\n",
    "    \n",
    "    lr = 0.01\n",
    "    \n",
    "    #NUMBER OF ESTIMATORS\n",
    "    param_test1 = {'n_estimators':np.arange(20,111,10).tolist()}\n",
    "    gsearch1 = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=lr, min_samples_split=500,\n",
    "                              min_samples_leaf=50,max_depth=8,max_features='sqrt', subsample=0.8,random_state=10), \n",
    "                   param_grid = param_test1, scoring=scoring,n_jobs=4,iid=False, cv=5, refit = False)\n",
    "    gsearch1.fit(trainArr, trainRes)\n",
    "    n_estimators = list(gsearch1.best_params_.values())[0]\n",
    "    display(gsearch1.best_params_)\n",
    "\n",
    "    param_test2 = {'max_depth':list(range(1,16,1)), 'min_samples_split':list(range(100,1001,100))}\n",
    "    gsearch2 = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=lr, n_estimators=n_estimators,\n",
    "                                            max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test2, scoring=scoring,n_jobs=4,iid=False, cv=5, refit = False)\n",
    "    gsearch2.fit(trainArr, trainRes)\n",
    "    display(gsearch2.best_params_)\n",
    "    max_depth=list(gsearch2.best_params_.values())[0]\n",
    "    min_samples_split = list(gsearch2.best_params_.values())[1]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test3 = {'min_samples_leaf':list(range(1,71,10))}\n",
    "    gsearch3 = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test3, scoring=scoring,n_jobs=4,iid=False, cv=5, refit = False)\n",
    "    gsearch3.fit(trainArr, trainRes)\n",
    "    display(gsearch3.best_params_)\n",
    "    min_samples_leaf = list(gsearch3.best_params_.values())[0]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test4 = {'max_features':range(5,20,2)}\n",
    "    gsearch4 = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                min_samples_leaf=min_samples_leaf, subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test4, scoring=scoring,n_jobs=4,iid=False, cv=5, refit = False)\n",
    "    gsearch4.fit(trainArr, trainRes)\n",
    "    display(gsearch4.best_params_)\n",
    "    max_features = list(gsearch4.best_params_.values())[0]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "    gsearch5=GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                min_samples_leaf=min_samples_leaf,max_features=max_features, random_state=10), \n",
    "                   param_grid = param_test5, scoring=scoring,n_jobs=4,iid=False, cv=5, refit = False)\n",
    "    gsearch5.fit(trainArr, trainRes)\n",
    "    display(gsearch5.best_params_)\n",
    "    subsample = list(gsearch5.best_params_.values())[0]\n",
    "\n",
    "    rf = GradientBoostingRegressor(learning_rate=lr/100, n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                subsample=subsample, max_features=max_features, min_samples_leaf=min_samples_leaf, random_state=10)\n",
    "    \n",
    "    rf.fit(trainArr, trainRes) # fit the data to the algorithm\n",
    "    \n",
    "    #predictions\n",
    "    results = rf.predict(testArr)\n",
    "    test['predictions_probability'] = results\n",
    "    \n",
    "    #plot the feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    \n",
    "    features = list(test)\n",
    "    sort_features = []\n",
    "    sort_import = []\n",
    "    for f in range(testArr.shape[1]):\n",
    "        sort_features.append(features[indices[f]])\n",
    "        sort_import.append(importances[indices[f]])\n",
    "\n",
    "    df = pd.DataFrame({'Indices': sort_features, 'Importance': sort_import})\n",
    "\n",
    "    feature_list = ['OrgCode', 'Timeofday', 'Modality', 'Age', 'Gender', 'Weekday']\n",
    "    feature_sums = []\n",
    "    print(\"Feature ranking:\")\n",
    "    for i in feature_list:\n",
    "        org = df[df['Indices'].str.contains(i)]\n",
    "        addition = org['Importance'].sum()\n",
    "        print(\"%a: %f\" % (i, addition))\n",
    "        feature_sums.append(addition)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(np.arange(len(feature_list)), np.asarray(feature_sums), \n",
    "            color=\"teal\", align=\"center\")\n",
    "    plt.xticks(np.arange(len(feature_list)), feature_list, rotation = 60)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xlim([-1, len(feature_list)])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold0 = gradient_boost_reg_CV(0, full_data)\n",
    "fold1 = gradient_boost_reg_CV(1, full_data)\n",
    "fold2 = gradient_boost_reg_CV(2, full_data)\n",
    "fold3 = gradient_boost_reg_CV(3, full_data)\n",
    "fold4 = gradient_boost_reg_CV(4, full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def binary_metrics (data):\n",
    "    #binarize the variable\n",
    "    data = data\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(data[\"Labels\"], data['Predictions']).ravel()\n",
    "\n",
    "    #Accuracy\n",
    "    acc  = round((tp + tn)/(tp + tn + fp + fn)*100 , 3)\n",
    "\n",
    "    #Recall\n",
    "    rec  = round(tp/(tp + fn)*100, 3)\n",
    "\n",
    "    #Precision\n",
    "    prec = round(tp/(tp + fp)*100,3)\n",
    "\n",
    "    #F1 Score\n",
    "    f1   = round(2*tp/((2*tp) + fp + fn)*100,3)\n",
    "    \n",
    "    metrics = [acc, rec, prec, f1]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b0 = binary_metrics(fold0)\n",
    "b1 = binary_metrics(fold1)\n",
    "b2 = binary_metrics(fold2)\n",
    "b3 = binary_metrics(fold3)\n",
    "b4 = binary_metrics(fold4)\n",
    "\n",
    "\n",
    "binary = pd.DataFrame([b0, b1, b2, b3, b4])\n",
    "binary.columns = ['Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 0', 'Fold 1', 'Fold 2', 'Fold 3', 'Fold 4']\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
